[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=8
width=640
height=640
channels=3
momentum=0.949
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00261
burn_in=1000
max_batches = 500500
policy=steps
steps=400000,450000
scales=.1,.1

mosaic=1

# ============ Backbone ============ #

# P1
[convolutional]
batch_normalize=1
filters=16
size=3
stride=2
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=16
groups=16
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=silu

[route]
layers=-7

[convolutional]
batch_normalize=1
filters=8
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=silu

# P2
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
groups=32
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear


[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
groups=32
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[route]
layers=-10

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

# P3
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
groups=64
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
groups=64
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
groups=64
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
groups=64
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[route]
layers=-18

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

# P4
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
groups=128
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
groups=128
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[route]
layers=-10

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

# P5
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
groups=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
groups=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
groups=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
groups=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[shortcut]
from=-4
activation=linear

[route]
layers=-18

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[route]
layers=-9

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[route]
layers=81

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=silu

# CHANGE to ROUTE_ATTN
[route_attn]
layers=-1, -4
heads=4
expansion=3
reduction=2
psm=2
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[route]
layers=59

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[route]
layers=-14

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[route]
layers=101

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

# CHANGE TO ROUTE ATTN
[route_attn]
layers=-3, -1
heads=4
expansion=3
reduction=2
psm=4
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -5

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=255
size=1
stride=1
pad=1
activation=linear

[yolo]
mask = 0,1,2
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6

[route]
layers=101

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=silu

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[route]
layers=-9

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=silu

[route]
layers=-1, -3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=255
size=1
stride=1
pad=1
activation=linear

[yolo]
mask = 3,4,5
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6

[route]
layers=96

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=silu

[convolutional]
batch_normalize=1
filters=255
size=1
stride=1
pad=1
activation=linear

[yolo]
mask = 6,7,8
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6